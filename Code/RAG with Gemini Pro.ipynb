{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG with Gemini Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "from RAG_Functions import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 1024, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding model\n",
    "embedding_model = SentenceTransformer(\"mixedbread-ai/mxbai-embed-large-v1\")\n",
    "embedding_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genai.GenerativeModel(\n",
      "    model_name='models/gemini-1.0-pro-latest',\n",
      "    generation_config={},\n",
      "    safety_settings={},\n",
      "    tools=None,\n",
      "    system_instruction=None,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "# Load API key from '~/Documents/Google/data-engineering-project.txt'\n",
    "with open(os.path.expanduser('~/Documents/Google/data-engineering-project.txt')) as f:\n",
    "    GOOGLE_API_KEY = f.read().strip()\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "chat_model = genai.GenerativeModel('gemini-1.0-pro-latest')\n",
    "print(chat_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Milvus Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import Collection, connections\n",
    "connections.connect(host='localhost', port='19530')\n",
    "collection = Collection(\"text_embeddings\")      # Get an existing collection.\n",
    "# index_params = {\n",
    "#     \"metric_type\": \"COSINE\",\n",
    "#     \"index_type\": \"FLAT\"#,\n",
    "#     #\"params\": {\"nlist\": 128}\n",
    "# }\n",
    "# collection.drop_index()\n",
    "# collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
    "# \"metric_type\": \"L2\",\n",
    "#     \"index_type\": \"IVF_FLAT\",\n",
    "#     \"params\": {\"nlist\": 128}\n",
    "collection.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['iCloud: What Is Personal Data at Apple?', 'iCloud: Details including salary, income, and assets information where collected, and information related to Apple-branded financial offerings\\nGovernment ID Data.', 'iCloud: Apple may collect data about you from other individuals     for example, if that individual has sent you a product or gift card, invited you to participate in an Apple service or forum, or shared content with you.', 'iCloud: Descriptions of how Apple handles personal data for certain individual services are available at apple.com/legal/privacy/data.', 'iCloud: You also can view this information at any time, either in Settings related to those features and/or online at apple.com/legal/privacy.']\n"
     ]
    }
   ],
   "source": [
    "# Chat with model\n",
    "input_text = input()\n",
    "\n",
    "# Get embedding of input\n",
    "input_embedding = get_mixedbread_of_query(embedding_model, input_text)\n",
    "\n",
    "# Start timing query\n",
    "start_time = time.time()\n",
    "\n",
    "# Top5 sentences\n",
    "top5_sentences = return_top_5_sentences(collection, input_embedding)\n",
    "\n",
    "# End timing query\n",
    "end_time = time.time()\n",
    "\n",
    "# query time\n",
    "query_time = end_time - start_time\n",
    "\n",
    "print(top5_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context That May Be Helpful (You May Disregard if Not Helpful):\n",
      "iCloud: What Is Personal Data at Apple?\n",
      "iCloud: Details including salary, income, and assets information where collected, and information related to Apple-branded financial offerings\n",
      "Government ID Data.\n",
      "iCloud: Apple may collect data about you from other individuals     for example, if that individual has sent you a product or gift card, invited you to participate in an Apple service or forum, or shared content with you.\n",
      "iCloud: Descriptions of how Apple handles personal data for certain individual services are available at apple.com/legal/privacy/data.\n",
      "iCloud: You also can view this information at any time, either in Settings related to those features and/or online at apple.com/legal/privacy.\n",
      "User Query:\n",
      "What data does Apple store about me?\n"
     ]
    }
   ],
   "source": [
    "# Construct prompt\n",
    "prompt_lines = [\"Context That May Be Helpful (You May Disregard if Not Helpful):\"] + top5_sentences + [\"User Query:\\n\" + input_text]\n",
    "prompt = \"\\n\".join(prompt_lines)\n",
    "print(prompt)\n",
    "\n",
    "#Context:\n",
    "#Document Name: <document_filename_1>\n",
    "#Information: <sentence_1>\n",
    "#Document Name: <document_filename_2>\n",
    "#Information: <sentence_2>\n",
    "#Document Name: <document_filename_3>\n",
    "#Information: <sentence_3>\n",
    "#Document Name: <document_filename_4>\n",
    "#Information: <sentence_4>\n",
    "#Document Name: <document_filename_5>\n",
    "#Information: <sentence_5>\n",
    "#<user_query>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- iCloud: Details including salary, income, and assets information where collected, and information related to Apple-branded financial offerings\n",
      "- Government ID Data\n",
      "- Data from other individuals who have interacted with you through Apple services\n"
     ]
    }
   ],
   "source": [
    "# Get response\n",
    "response = chat_model.generate_content(prompt)\n",
    "\n",
    "# from IPython.display import Markdown\n",
    "# import textwrap\n",
    "# def to_markdown(text):\n",
    "#   text = text.replace('â€¢', '  *')\n",
    "#   return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
    "# to_markdown(response.text)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(top5_sentences.get('sentence'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for hits in top5_sentences:\n",
    "#     # Get ids\n",
    "#     print(hits.ids)\n",
    "    \n",
    "#     # Get distances\n",
    "#     print(hits.distances)\n",
    "    \n",
    "#     for hit in hits:\n",
    "#         # Get id\n",
    "#         print(hit.id)\n",
    "        \n",
    "#         # Get distance\n",
    "#         print(hit.distance) # hit.score\n",
    "        \n",
    "#         # Get vector\n",
    "#         #hit.vector\n",
    "        \n",
    "#         # Get output field\n",
    "#         print(hit.get(\"sentence\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tokenize\n",
    "# input_ids = chat_tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# outputs = chat_model.generate(input_ids)\n",
    "# print(chat_tokenizer.decode(outputs[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_engineering_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
