{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG with Gemini Pro\n",
    "\n",
    "Note: Place your Google API key in the Google API Key folder of the directory this code is in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "from RAG_Functions import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ijyli\\miniforge3\\envs\\data_engineering_project\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Packages\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 1024, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding model\n",
    "embedding_model = SentenceTransformer(\"mixedbread-ai/mxbai-embed-large-v1\")\n",
    "embedding_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genai.GenerativeModel(\n",
      "    model_name='models/gemini-1.0-pro-latest',\n",
      "    generation_config={},\n",
      "    safety_settings={},\n",
      "    tools=None,\n",
      "    system_instruction=None,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "# Load API key from './Google API Key/data-engineering-project.txt'\n",
    "with open(os.path.expanduser('./Google/data-engineering-project.txt')) as f:\n",
    "    GOOGLE_API_KEY = f.read().strip()\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "chat_model = genai.GenerativeModel('gemini-1.0-pro-latest')\n",
    "print(chat_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Milvus Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import Collection, connections\n",
    "connections.connect(host='localhost', port='19530')\n",
    "collection = Collection(\"text_embeddings\")      # Get an existing collection.\n",
    "# index_params = {\n",
    "#     \"metric_type\": \"COSINE\",\n",
    "#     \"index_type\": \"FLAT\"#,\n",
    "#     #\"params\": {\"nlist\": 128}\n",
    "# }\n",
    "# collection.drop_index()\n",
    "# collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
    "# \"metric_type\": \"L2\",\n",
    "#     \"index_type\": \"IVF_FLAT\",\n",
    "#     \"params\": {\"nlist\": 128}\n",
    "collection.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AppleServices: Apple may disclose any information we have about you (including your identity) if we determine that such disclosure is necessary in connection with any investigation or complaint regarding your use of the Site, or to identify, contact or bring legal action against someone who may be causing injury to or interference with (either intentionally or unintentionally) Apple   s rights or property, or the rights or property of visitors to or users of the Site, including Apple   s customers.', 'AppleServices: Apple may disclose any information we have about you (including your identity) if we determine that such disclosure is necessary in connection with any investigation or complaint regarding your use of the Site, or to identify, contact or bring legal action against someone who may be causing injury to or interference with (either intentionally or unintentionally) Apple   s rights or property, or the rights or property of visitors to or users of the Site, including Apple   s customers.', 'AppleServices: You may be asked to provide your personal information anytime you are in contact with Apple or an Apple affiliated company.', 'AppleServices: Apple does not sell your personal information.', 'AppleServices: It may be necessary     by law, legal process, litigation, and/or requests from public and governmental authorities within or outside your country of residence     for Apple to disclose your personal information.']\n"
     ]
    }
   ],
   "source": [
    "# Chat with model\n",
    "input_text = input()\n",
    "\n",
    "# Get embedding of input\n",
    "input_embedding = get_mixedbread_of_query(embedding_model, input_text)\n",
    "\n",
    "# Start timing query\n",
    "start_time = time.time()\n",
    "\n",
    "# Top5 sentences\n",
    "top5_sentences, documents_cited, milvus_query_time = return_top_5_sentences(collection, input_embedding)\n",
    "\n",
    "# End timing query\n",
    "end_time = time.time()\n",
    "\n",
    "# query time\n",
    "query_time = end_time - start_time\n",
    "\n",
    "print(top5_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context That May Be Helpful (You May Disregard if Not Helpful):\n",
      "AppleServices: Apple may disclose any information we have about you (including your identity) if we determine that such disclosure is necessary in connection with any investigation or complaint regarding your use of the Site, or to identify, contact or bring legal action against someone who may be causing injury to or interference with (either intentionally or unintentionally) Apple   s rights or property, or the rights or property of visitors to or users of the Site, including Apple   s customers.\n",
      "AppleServices: Apple may disclose any information we have about you (including your identity) if we determine that such disclosure is necessary in connection with any investigation or complaint regarding your use of the Site, or to identify, contact or bring legal action against someone who may be causing injury to or interference with (either intentionally or unintentionally) Apple   s rights or property, or the rights or property of visitors to or users of the Site, including Apple   s customers.\n",
      "AppleServices: You may be asked to provide your personal information anytime you are in contact with Apple or an Apple affiliated company.\n",
      "AppleServices: Apple does not sell your personal information.\n",
      "AppleServices: It may be necessary     by law, legal process, litigation, and/or requests from public and governmental authorities within or outside your country of residence     for Apple to disclose your personal information.\n",
      "User Query:\n",
      "Does Apple sell my personal information?\n"
     ]
    }
   ],
   "source": [
    "# Construct prompt\n",
    "prompt_lines = [\"Context That May Be Helpful (You May Disregard if Not Helpful):\"] + top5_sentences + [\"User Query:\\n\" + input_text]\n",
    "prompt = \"\\n\".join(prompt_lines)\n",
    "print(prompt)\n",
    "\n",
    "#Context:\n",
    "#Document Name: <document_filename_1>\n",
    "#Information: <sentence_1>\n",
    "#Document Name: <document_filename_2>\n",
    "#Information: <sentence_2>\n",
    "#Document Name: <document_filename_3>\n",
    "#Information: <sentence_3>\n",
    "#Document Name: <document_filename_4>\n",
    "#Information: <sentence_4>\n",
    "#Document Name: <document_filename_5>\n",
    "#Information: <sentence_5>\n",
    "#<user_query>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get response\n",
    "response = chat_model.generate_content(prompt)\n",
    "\n",
    "# from IPython.display import Markdown\n",
    "# import textwrap\n",
    "# def to_markdown(text):\n",
    "#   text = text.replace('â€¢', '  *')\n",
    "#   return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
    "# to_markdown(response.text)\n",
    "#print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, Apple does not sell your personal information.\n",
      "Documents Cited: AppleServices_WebsiteTermsofService.txt, AppleServices_PrivacyPolicy.txt, AppleServices_ApplicationBasedServices.txt\n",
      "Milvus Query Time: 0.38 seconds\n"
     ]
    }
   ],
   "source": [
    "# Format response for user\n",
    "response_for_user = response.text + \"\\nDocuments Cited: \" + ', '.join(documents_cited) + \"\\nMilvus Query Time: \" + str(round(milvus_query_time, 2)) + ' seconds'\n",
    "print(response_for_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(top5_sentences.get('sentence'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for hits in top5_sentences:\n",
    "#     # Get ids\n",
    "#     print(hits.ids)\n",
    "    \n",
    "#     # Get distances\n",
    "#     print(hits.distances)\n",
    "    \n",
    "#     for hit in hits:\n",
    "#         # Get id\n",
    "#         print(hit.id)\n",
    "        \n",
    "#         # Get distance\n",
    "#         print(hit.distance) # hit.score\n",
    "        \n",
    "#         # Get vector\n",
    "#         #hit.vector\n",
    "        \n",
    "#         # Get output field\n",
    "#         print(hit.get(\"sentence\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tokenize\n",
    "# input_ids = chat_tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# outputs = chat_model.generate(input_ids)\n",
    "# print(chat_tokenizer.decode(outputs[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_engineering_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
